{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buckets creation, and notifications configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T16:17:40.628421Z",
     "start_time": "2021-05-03T16:17:40.624173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access Key Id: W92D9P7YA2ZGDW41M0D5\n",
      "Access Key: 1P8fhzRq6WKkiPnC3hbPEv0lsPNICJTIsWv1VDjX\n",
      "S3 Endpoint: http://ceph-nano-0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Since every user gets their own namespace, we'll be using the same base name\n",
    "# for all the buckets. If you're using shared infrastructure, pick a unique\n",
    "# value for this.\n",
    "bucket_base_name = 'images'\n",
    "\n",
    "# Our access key and id were entered as environment variables earlier in the\n",
    "# lab.\n",
    "aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "print(\"Access Key Id: %s\"% (aws_access_key_id,))\n",
    "print(\"Access Key: %s\"% (aws_secret_access_key,))\n",
    "\n",
    "# This value was defined when we created our Data Hub instance. Environment\n",
    "# variables can be predefined as a part of the KFDef.\n",
    "endpoint_url = os.getenv('S3_ENDPOINT_URL')\n",
    "\n",
    "print(\"S3 Endpoint: %s\"% (endpoint_url,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Of course we'll need some libraries, so import them by running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T16:17:42.446064Z",
     "start_time": "2021-05-03T16:17:42.443664Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import botocore\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 connections\n",
    "The boto3 is the standard library from AWS to interact with all their services. As Ceph is compatible with S3, we can directly use this library to interact with the storage. So first, let's create the clients (you can see we are using some parameters we defined earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T16:17:43.973281Z",
     "start_time": "2021-05-03T16:17:43.964104Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3', '',\n",
    "                endpoint_url = os.getenv('S3_ENDPOINT_URL'),\n",
    "                aws_access_key_id = aws_access_key_id,\n",
    "                aws_secret_access_key = aws_secret_access_key,\n",
    "                config=botocore.client.Config(signature_version = 's3'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create buckets\n",
    "Now that we can connect to the storage, we can create our buckets. Run the first cell, which will define a \"creation function\" (an S3 API call using the client we created). Then the second cell that will create the 3 buckets we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T16:17:45.790243Z",
     "start_time": "2021-05-03T16:17:45.787770Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name):\n",
    "    result = s3.create_bucket(Bucket=bucket_name)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T16:17:46.814786Z",
     "start_time": "2021-05-03T16:17:46.531539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'tx00000000000000000000b-006090222a-1010-default',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-request-id': 'tx00000000000000000000b-006090222a-1010-default',\n",
       "   'content-length': '0',\n",
       "   'date': 'Mon, 03 May 2021 16:17:46 GMT',\n",
       "   'connection': 'Keep-Alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_bucket(bucket_base_name)\n",
    "create_bucket(bucket_base_name+'-processed')\n",
    "create_bucket(bucket_base_name+'-anonymized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification\n",
    "As the previous output may have been cryptic (and anyway it's always good to check), let's list all the buckets and verify the indeed have been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T16:17:48.260921Z",
     "start_time": "2021-05-03T16:17:48.249792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\n",
      "images-anonymized\n",
      "images-processed\n"
     ]
    }
   ],
   "source": [
    "for bucket in s3.list_buckets()['Buckets']:\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make buckets public read\n",
    "Our Grafana dashboard will display the last image from each bucket. Instead of setting up a dedicated web server, we can directly query our object stores to retrieve the images. For this to work we have to make our bucket \"public-readable\". This is done by applying to each this bucket policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-03T16:17:49.579961Z",
     "start_time": "2021-05-03T16:17:49.526622Z"
    }
   },
   "outputs": [],
   "source": [
    "for bucket in s3.list_buckets()['Buckets']:\n",
    "    bucket_policy = {\n",
    "                      \"Version\":\"2012-10-17\",\n",
    "                      \"Statement\":[\n",
    "                        {\n",
    "                          \"Sid\":\"AddPerm\",\n",
    "                          \"Effect\":\"Allow\",\n",
    "                          \"Principal\": \"*\",\n",
    "                          \"Action\":[\"s3:GetObject\"],\n",
    "                          \"Resource\":[\"arn:aws:s3:::{0}/*\".format(bucket['Name'])]\n",
    "                        }\n",
    "                      ]\n",
    "                    }\n",
    "    bucket_policy = json.dumps(bucket_policy)\n",
    "    s3.put_bucket_policy(Bucket=bucket['Name'], Policy=bucket_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
